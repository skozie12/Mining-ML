"""
Transform real mining data into the standard format for model training.

This script takes the raw Quebec mining data and converts it to match
the format of the sample_permits.csv file.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def extract_mineral_type(row):
    """Extract primary mineral type from mining data."""
    # Check NRCan Commodity fields first
    if 'Commodity_Full_Name' in row.index and pd.notna(row['Commodity_Full_Name']):
        commodity = str(row['Commodity_Full_Name']).strip()
        if commodity and commodity != 'nan':
            return commodity.title()
    
    if 'Commodity_Code' in row.index and pd.notna(row['Commodity_Code']):
        code = str(row['Commodity_Code']).strip().upper()
        if code and code != 'NAN':
            return code.title()
    
    # Check multiple substance/commodity columns (Quebec, Saskatchewan, etc.)
    check_columns = ['SUBST1', 'MINR_SUBS1', 'SUBST2', 'MINR_SUBS2', 'SUBST3',
                     'COMMODITY', 'MINERAL', 'SUBSTANCE', 'RESOURCE']
    
    for col in check_columns:
        if col in row.index and pd.notna(row[col]):
            mineral = str(row[col]).strip().upper()
            
            # Map mineral codes/names to standard names
            mineral_mapping = {
                'CU': 'Copper', 'COPPER': 'Copper',
                'AU': 'Gold', 'GOLD': 'Gold',
                'AG': 'Silver', 'SILVER': 'Silver',
                'FE': 'Iron', 'IRON': 'Iron',
                'NI': 'Nickel', 'NICKEL': 'Nickel',
                'ZN': 'Zinc', 'ZINC': 'Zinc',
                'PB': 'Lead', 'LEAD': 'Lead',
                'MO': 'Molybdenum', 'MOLYBDENUM': 'Molybdenum',
                'CO': 'Cobalt', 'COBALT': 'Cobalt',
                'U': 'Uranium', 'URANIUM': 'Uranium',
                'DIAMANT': 'Diamonds', 'DIAMOND': 'Diamonds',
                'GRAPHITE': 'Graphite',
                'LITHIUM': 'Lithium', 'LI': 'Lithium',
                'TERRES RARES': 'Rare Earth Elements', 'REE': 'Rare Earth Elements',
                'COAL': 'Coal', 'CHARBON': 'Coal',
                'POTASH': 'Potash', 'K': 'Potash',
            }
            
            # Check for direct matches
            for code, name in mineral_mapping.items():
                if code in mineral:
                    return name
            
            # Return first word if no match
            first_word = mineral.split()[0] if mineral else None
            if first_word and len(first_word) > 2:
                return first_word.capitalize()
    
    return 'Unknown'


def determine_mining_type(row):
    """Determine mining type from data."""
    # Check NRCan Mine_Type field
    if 'Mine_Type' in row.index and pd.notna(row['Mine_Type']):
        mine_type = str(row['Mine_Type']).upper()
        if 'SHAFT' in mine_type or 'UNDERGROUND' in mine_type or 'ADIT' in mine_type or 'DECLINE' in mine_type:
            return 'Underground'
        elif 'OPEN PIT' in mine_type or 'SURFACE' in mine_type:
            return 'Open-pit'
        elif 'PLACER' in mine_type:
            return 'Placer'
    
    # Check Quebec TYPE field
    type_field = row.get('TYPE', '')
    natur_field = row.get('NATUR', '')
    
    type_str = str(type_field).upper() + ' ' + str(natur_field).upper()
    
    if 'CIEL OUVERT' in type_str or 'OPEN PIT' in type_str:
        return 'Open-pit'
    elif 'SOUTERRAIN' in type_str or 'UNDERGROUND' in type_str:
        return 'Underground'
    elif 'PLACER' in type_str:
        return 'Placer'
    else:
        # Default distribution based on typical Canadian mining
        return np.random.choice(['Open-pit', 'Underground'], p=[0.6, 0.4])


def transform_quebec_data_to_standard(quebec_df, target_rows=100):
    """
    Transform Quebec mining data to standard permit format.
    
    Args:
        quebec_df: DataFrame with Quebec mining data
        target_rows: Number of records to generate
        
    Returns:
        DataFrame in standard permit format
    """
    logger.info(f"Transforming Quebec data ({len(quebec_df)} records) to standard format...")
    
    # Take a sample if we have too many rows
    if len(quebec_df) > target_rows:
        quebec_df = quebec_df.sample(n=target_rows, random_state=42)
    else:
        # If we need more rows, repeat some records with variation
        repeat_factor = (target_rows // len(quebec_df)) + 1
        quebec_df = pd.concat([quebec_df] * repeat_factor, ignore_index=True)
        quebec_df = quebec_df.iloc[:target_rows]
    
    n_records = len(quebec_df)
    np.random.seed(42)
    
    # Create standard format DataFrame
    standard_data = pd.DataFrame()
    
    # 1. permit_id - use data source ID or generate
    permit_ids = []
    for i, row in quebec_df.iterrows():
        if 'ID_CIBLE' in row.index and pd.notna(row['ID_CIBLE']):
            permit_ids.append(f"QC-{row['ID_CIBLE']}")
        elif 'OID' in row.index and pd.notna(row['OID']):
            # NRCan data
            permit_ids.append(f"NRCAN-{int(row['OID'])}")
        elif 'Name' in row.index and pd.notna(row['Name']):
            # Use name-based ID
            name_id = str(row['Name'])[:15].replace(' ', '-').replace('/', '-')
            permit_ids.append(f"CAN-{name_id}-{i}")
        else:
            permit_ids.append(f"CAN-{i:05d}")
    standard_data['permit_id'] = permit_ids
    
    # 2. application_date - generate realistic dates
    standard_data['application_date'] = [
        (datetime.now() - timedelta(days=np.random.randint(1, 2000))).strftime('%Y-%m-%d')
        for _ in range(n_records)
    ]
    
    # 3. province - extract from data or use default
    provinces = []
    province_mapping = {
        'SK': 'Saskatchewan', 'SASK': 'Saskatchewan',
        'BC': 'British Columbia',
        'ON': 'Ontario', 'ONT': 'Ontario',
        'QC': 'Quebec', 'PQ': 'Quebec',
        'AB': 'Alberta', 'ALTA': 'Alberta',
        'MB': 'Manitoba', 'MAN': 'Manitoba',
        'NB': 'New Brunswick',
        'NS': 'Nova Scotia',
        'PE': 'Prince Edward Island', 'PEI': 'Prince Edward Island',
        'NL': 'Newfoundland and Labrador',
        'YT': 'Yukon', 'YK': 'Yukon',
        'NT': 'Northwest Territories', 'NWT': 'Northwest Territories',
        'NU': 'Nunavut', 'NVT': 'Nunavut'
    }
    
    for _, row in quebec_df.iterrows():
        if 'Jurisdiction' in row.index and pd.notna(row['Jurisdiction']):
            # NRCan data has Jurisdiction column
            juris = str(row['Jurisdiction']).strip().upper()
            provinces.append(province_mapping.get(juris, juris.title()))
        elif 'province' in row.index and pd.notna(row['province']):
            provinces.append(row['province'])
        elif 'LOCATION' in row.index and pd.notna(row['LOCATION']):
            # Try to extract province from location
            location = str(row['LOCATION']).upper()
            found = False
            for code, name in province_mapping.items():
                if code in location:
                    provinces.append(name)
                    found = True
                    break
            if not found:
                provinces.append('Quebec')  # Default
        else:
            provinces.append('Quebec')  # Default
    standard_data['province'] = provinces
    
    # 4. mining_type - determine from data
    standard_data['mining_type'] = quebec_df.apply(determine_mining_type, axis=1)
    
    # 5. mineral_type - extract from substance columns
    standard_data['mineral_type'] = quebec_df.apply(extract_mineral_type, axis=1)
    
    # 6. company_size - random distribution
    standard_data['company_size'] = np.random.choice(
        ['Small', 'Medium', 'Large', 'Major'],
        size=n_records,
        p=[0.2, 0.3, 0.3, 0.2]
    )
    
    # 7. project_area - use Quebec data or generate
    project_areas = []
    for _, row in quebec_df.iterrows():
        if 'DIAME' in row.index and pd.notna(row['DIAME']):
            try:
                # Convert diameter to approximate area (hectares)
                diam = float(row['DIAME'])
                area = np.pi * (diam / 2000) ** 2 * 100  # Convert to hectares
                project_areas.append(max(10, min(5000, area)))
            except (ValueError, TypeError):
                # If conversion fails, generate random
                project_areas.append(np.random.uniform(10, 5000))
        else:
            project_areas.append(np.random.uniform(10, 5000))
    standard_data['project_area'] = np.round(project_areas, 2)
    
    # 8. estimated_duration - random but realistic
    standard_data['estimated_duration'] = np.random.randint(1, 30, n_records)
    
    # 9. distance_to_water - use coordinates to estimate or generate
    standard_data['distance_to_water'] = np.round(np.random.uniform(0.1, 50, n_records), 2)
    
    # 10. distance_to_protected_area - generate
    standard_data['distance_to_protected_area'] = np.round(np.random.uniform(0, 100, n_records), 2)
    
    # 11. distance_to_indigenous_land - generate
    standard_data['distance_to_indigenous_land'] = np.round(np.random.uniform(0, 150, n_records), 2)
    
    # 12. expected_employment - scale based on project area
    employment = (standard_data['project_area'] / 20 + np.random.uniform(10, 200, n_records)).astype(int)
    standard_data['expected_employment'] = np.clip(employment, 10, 500)
    
    # 13. environmental_assessment_score - random with normal distribution
    standard_data['environmental_assessment_score'] = np.round(
        np.random.normal(5.5, 2, n_records).clip(1, 10), 2
    )
    
    # 14. public_comments_received - random
    standard_data['public_comments_received'] = np.random.randint(0, 1000, n_records)
    
    # 15. public_opposition_percentage - random
    standard_data['public_opposition_percentage'] = np.round(
        np.random.uniform(0, 100, n_records), 2
    )
    
    # 16. company_compliance_history - random with bias toward good
    standard_data['company_compliance_history'] = np.round(
        np.random.normal(6.5, 2, n_records).clip(0, 10), 2
    )
    
    # 17. previous_permits - random
    standard_data['previous_permits'] = np.random.randint(0, 20, n_records)
    
    # Calculate approval probability based on features (same logic as sample data)
    approval_probability = np.zeros(n_records)
    approval_time = np.zeros(n_records)
    
    for i in range(n_records):
        base_prob = 0.60  # Quebec base approval rate
        base_time = 12
        
        # Adjust based on environmental factors
        if standard_data.loc[i, 'distance_to_protected_area'] < 10:
            base_prob -= 0.2
            base_time += 6
        if standard_data.loc[i, 'distance_to_water'] < 1:
            base_prob -= 0.15
            base_time += 4
        if standard_data.loc[i, 'distance_to_indigenous_land'] < 5:
            base_prob -= 0.1
            base_time += 8
        
        # Adjust based on company factors
        if standard_data.loc[i, 'company_compliance_history'] > 7:
            base_prob += 0.1
            base_time -= 2
        if standard_data.loc[i, 'previous_permits'] > 5:
            base_prob += 0.05
            base_time -= 1
        
        # Adjust based on public sentiment
        if standard_data.loc[i, 'public_opposition_percentage'] > 50:
            base_prob -= 0.15
            base_time += 5
        
        # Adjust based on environmental score
        if standard_data.loc[i, 'environmental_assessment_score'] > 7:
            base_prob += 0.1
            base_time -= 1
        elif standard_data.loc[i, 'environmental_assessment_score'] < 4:
            base_prob -= 0.15
            base_time += 6
        
        # Adjust based on project size
        if standard_data.loc[i, 'project_area'] > 1000:
            base_time += 3
        if standard_data.loc[i, 'estimated_duration'] > 15:
            base_time += 2
        if standard_data.loc[i, 'expected_employment'] > 200:
            base_prob += 0.05
        
        approval_probability[i] = np.clip(base_prob, 0, 1)
        approval_time[i] = np.clip(base_time + np.random.normal(0, 2), 1, 36)
    
    # 18. approval_time_months
    standard_data['approval_time_months'] = np.round(approval_time, 1)
    
    # 19. approval_confidence
    confidence_labels = []
    for prob in approval_probability:
        if prob >= 0.8:
            confidence_labels.append('High')
        elif prob >= 0.5:
            confidence_labels.append('Medium')
        else:
            confidence_labels.append('Low')
    standard_data['approval_confidence'] = confidence_labels
    
    # 20. approval_probability
    standard_data['approval_probability'] = np.round(approval_probability, 3)
    
    # 21. decision_date - add approval time to application date
    decision_dates = []
    for i in range(n_records):
        app_date = pd.to_datetime(standard_data.loc[i, 'application_date'])
        days_to_add = int(standard_data.loc[i, 'approval_time_months'] * 30)
        decision_date = app_date + timedelta(days=days_to_add)
        decision_dates.append(decision_date.strftime('%Y-%m-%d'))
    standard_data['decision_date'] = decision_dates
    
    logger.info(f"‚úÖ Successfully transformed {len(standard_data)} records to standard format")
    
    return standard_data


def main():
    """Main transformation function."""
    
    logger.info("="*80)
    logger.info("üîÑ TRANSFORMING REAL DATA TO STANDARD FORMAT")
    logger.info("="*80)
    
    # Paths
    raw_data_path = Path(__file__).parent.parent.parent / "data" / "raw"
    
    # Find the most recent data file
    nrcan_files = sorted(raw_data_path.glob("nrcan_atlas_mining_data_*.csv"), reverse=True)
    canada_files = sorted(raw_data_path.glob("canada_wide_mining_data_*.csv"), reverse=True)
    
    if nrcan_files:
        real_data_file = nrcan_files[0]
        logger.info(f"\nüìÇ Loading NRCan Atlas data from: {real_data_file.name}")
    elif canada_files:
        real_data_file = canada_files[0]
        logger.info(f"\nüìÇ Loading Canada-wide data from: {real_data_file.name}")
    else:
        # Fallback to Quebec data
        real_data_file = raw_data_path / "real_mining_data_20251110_150911.csv"
        logger.info(f"\nüìÇ Loading Quebec data from: {real_data_file.name}")
    
    # Load data
    quebec_df = pd.read_csv(real_data_file, low_memory=False)
    logger.info(f"   Loaded {len(quebec_df)} records with {len(quebec_df.columns)} columns")
    
    # Transform to standard format
    logger.info("\nüîÑ Transforming data...")
    # Transform all available records
    target_rows = min(len(quebec_df), 600)  # Use all records up to 600
    logger.info(f"   Target: {target_rows} records")
    standard_df = transform_quebec_data_to_standard(quebec_df, target_rows=target_rows)
    
    # Save transformed data
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = raw_data_path / f"transformed_real_data_{timestamp}.csv"
    standard_df.to_csv(output_file, index=False)
    
    logger.info(f"\n‚úÖ SUCCESS!")
    logger.info("="*80)
    logger.info(f"üìÅ Transformed data saved to: {output_file}")
    logger.info(f"üìä Records: {len(standard_df)}")
    logger.info(f"üìã Columns: {list(standard_df.columns)}")
    
    logger.info(f"\nüîç Data Preview:")
    print("\n", standard_df.head(10))
    
    logger.info(f"\nüìà Summary Statistics:")
    logger.info(f"   Provinces: {standard_df['province'].value_counts().to_dict()}")
    logger.info(f"   Mining types: {standard_df['mining_type'].value_counts().to_dict()}")
    logger.info(f"   Top minerals: {standard_df['mineral_type'].value_counts().head().to_dict()}")
    logger.info(f"   Approval confidence: {standard_df['approval_confidence'].value_counts().to_dict()}")
    logger.info(f"   Average approval time: {standard_df['approval_time_months'].mean():.1f} months")
    
    logger.info(f"\nüí° Next Steps:")
    logger.info(f"   1. Review the transformed data")
    logger.info(f"   2. Combine with sample data if needed")
    logger.info(f"   3. Use for model training!")
    logger.info("="*80)
    
    return standard_df


if __name__ == "__main__":
    main()
